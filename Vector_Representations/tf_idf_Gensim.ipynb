{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Isaac\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some raw document\n",
    "raw_documents = ['I love tacos.',\n",
    "                 'She run with the chicken.',\n",
    "                 'I dont choose to take a nap. The nap choose me.',\n",
    "                  'That man is nice as pie with ice cream.',\n",
    "                   'That pizza is an affront to nature.' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's tokenize using NLTK\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function that makes token\n",
    "def get_tokens(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'love', 'tacos', '.'], ['She', 'run', 'with', 'the', 'chicken', '.'], ['I', 'dont', 'choose', 'to', 'take', 'a', 'nap', '.', 'The', 'nap', 'choose', 'me', '.'], ['That', 'man', 'is', 'nice', 'as', 'pie', 'with', 'ice', 'cream', '.'], ['That', 'pizza', 'is', 'an', 'affront', 'to', 'nature', '.']]\n"
     ]
    }
   ],
   "source": [
    "# A Gensim document is a list of tokens\n",
    "gen_docs = [get_tokens(text) for text in raw_documents]\n",
    "print(gen_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dictionarys: 29\n",
      "0 .\n",
      "1 I\n",
      "2 love\n",
      "3 tacos\n",
      "4 She\n",
      "5 chicken\n",
      "6 run\n",
      "7 the\n",
      "8 with\n",
      "9 The\n",
      "10 a\n",
      "11 choose\n",
      "12 dont\n",
      "13 me\n",
      "14 nap\n",
      "15 take\n",
      "16 to\n",
      "17 That\n",
      "18 as\n",
      "19 cream\n",
      "20 ice\n",
      "21 is\n",
      "22 man\n",
      "23 nice\n",
      "24 pie\n",
      "25 affront\n",
      "26 an\n",
      "27 nature\n",
      "28 pizza\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary from a list of documents\n",
    "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "num_words = len(dictionary)\n",
    "print(\"number of dictionarys: {}\".format(num_words))\n",
    "for idx,word in dictionary.items():\n",
    "    print(idx,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[7])\n",
    "print(dictionary.id2token[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (2, 3), (3, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Creating a bag of words\n",
    "# Note that \"!\" is not listed because order is lost\n",
    "# A bag of words is tf term frequency of tf-idf\n",
    "bow_doc = dictionary.doc2bow(['I', 'love', 'love', 'love', 'tacos','!'])\n",
    "print (bow_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1)], [(0, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)], [(0, 2), (1, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1)], [(0, 1), (8, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)], [(0, 1), (16, 1), (17, 1), (21, 1), (25, 1), (26, 1), (27, 1), (28, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Creating corpus\n",
    "# A corpus is a list of bag words\n",
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "print (corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel<num_docs=5, num_nnz=38>\n"
     ]
    }
   ],
   "source": [
    "# Create tf-idf model from corpus\n",
    "# num_nnz is the number of tokens \n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gensim doc : ['I', 'love', 'tacos', '.']\n",
      "coupus     : [(0, 1), (1, 1), (2, 1), (3, 1)]\n",
      "tf_idf     : [(1, 0.37344696513776354), (2, 0.6559486886294514), (3, 0.6559486886294514)]\n"
     ]
    }
   ],
   "source": [
    "# show document in text form, bag of words, and tf-idf\n",
    "# value for I is lower because occurs multiple times.\n",
    "# value for '.' is 0 because it occurs in all sentence \n",
    "\n",
    "print(\"Gensim doc : {}\".format(gen_docs[0]))\n",
    "print(\"coupus     : {}\".format(corpus[0]))\n",
    "print(\"tf_idf     : {}\".format(tf_idf[corpus][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (28, 1)]\n",
      "[(1, 0.37344696513776354), (2, 0.6559486886294514), (28, 0.6559486886294514)]\n"
     ]
    }
   ],
   "source": [
    "# show bag of words and tf-idf for new words\n",
    "bow = dictionary.doc2bow(['I','love', 'pizza', '.'])\n",
    "print(bow)\n",
    "print(tf_idf[bow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity measure \n",
    "doc = \"hello I am love.\"\n",
    "sims = gensim.similarities.Similarity(doc, tf_idf[corpus],num_features = len(dictionary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity<5 documents in 0 shards stored under hello I am love.>\n"
     ]
    }
   ],
   "source": [
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicken', 'with', 'tacos', 'love']\n",
      "[(2, 1), (3, 1), (5, 1), (8, 1)]\n",
      "[(2, 0.5484803253891997), (3, 0.5484803253891997), (5, 0.5484803253891997), (8, 0.31226270667960454)]\n"
     ]
    }
   ],
   "source": [
    "# Create query document and convert into tf-idf\n",
    "query_doc = \"chicken with tacos love\".split()\n",
    "print(query_doc)\n",
    "query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "print(query_doc_bow)\n",
    "query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "print(query_doc_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
